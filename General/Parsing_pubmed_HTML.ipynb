{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8de4cb6-63ca-41b7-b185-c629d02f4f96",
   "metadata": {
    "tags": []
   },
   "source": [
    "I think I need to make a custom parser because I cannot find anyone that is parsing the htmls pulled from pubmed. I need to look at some of these HTMLs (at least 5) and see if there is a custom structure that I can highjack.\n",
    "\n",
    "The only thing I found was this: https://github.com/natc79/PubMed/blob/master/PubMedDownloader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b31ed8-3eb7-4bab-b336-53f6b287fa5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import unicodedata\n",
    "import csv\n",
    "import os\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f10a2-1912-481e-bb6b-af5445fa8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_search_page(self, parser):\n",
    "    \"\"\"Parses general page of pubmed and insert into database.\n",
    "    TODO:  Search multiple pages (right now only gets first page)\n",
    "    need to return\n",
    "    \"\"\"\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # parse one page of results\n",
    "    results = parser.find_all('div', {'class':'rslt'})\n",
    "    for res in results:\n",
    "        #print(res)\n",
    "        tempdata = {}\n",
    "        temp = res.find('p', {'class':'title'})\n",
    "        print(temp)\n",
    "        tempdata['title'] = temp.text\n",
    "        tempdata['href'] = temp.find('a',{'href':True})['href']\n",
    "        tempdata['desc'] = res.find('p',{'class':'desc'}).text\n",
    "        temp = res.find('p',{'class':'details'})\n",
    "        tempdata['jrnl'] = temp.text\n",
    "        if tempdata['title'] != '':\n",
    "            cols = []\n",
    "            for key, value in tempdata.items():\n",
    "                cols.append(value.strip('\\n'))\n",
    "            data.append(cols)\n",
    "            print(data)\n",
    "\n",
    "    with open(self.outdir + 'pubmed-%s.csv' % (self.date), 'w', newline='') as f:\n",
    "        w = csv.writer(f, delimiter=',')\n",
    "        w.writerow(['title','href','desc','details'])\n",
    "        for d in data:\n",
    "            w.writerow(d)\n",
    "\n",
    "    # get the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd92e4-9ecc-4784-9446-cd789af2858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_page(self, searchterm):\n",
    "    \"\"\"Get search results from pubmed for particular search term.\"\"\"\n",
    "\n",
    "    url = self.url + '?term=%s&cmd=DetailsSearch' % (searchterm)\n",
    "    print(url)\n",
    "    page = urllib.request.urlopen(url)\n",
    "    parser = BeautifulSoup(page,'html.parser')\n",
    "    randnum = random.randint(3,10) \n",
    "    time.sleep(randnum)\n",
    "    self.parse_search_page(parser)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
